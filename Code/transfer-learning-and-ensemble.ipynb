{"cells":[{"cell_type":"markdown","metadata":{},"source":["Importing deepstack for powerful ensembles, [more info](https://github.com/jcborges/DeepStack)"]},{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["# !pip install deepstack"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["# import splitfolders\n","# splitfolders.ratio('/home/bce19229/19bce229/Dataset/CDS/Class-Divided-SET/','/home/bce19229/19bce229/Dataset/CDS/Class-Divided-SET/Output',seed=1337, ratio=(.8, 0.1,0.1))"]},{"cell_type":"markdown","metadata":{},"source":["**Importing essential pacakages**"]},{"cell_type":"code","execution_count":3,"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2022-12-11 15:53:25.488605: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"]}],"source":["# import pandas as pd\n","import numpy as np\n","import os\n","import tensorflow as tf\n","from tensorflow.keras.layers import Flatten,Dense,Dropout,BatchNormalization\n","from tensorflow.keras.models import Model,Sequential\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n","from tensorflow.keras.layers import PReLU\n","from tensorflow.keras.optimizers import RMSprop\n","from tensorflow.keras.callbacks import ReduceLROnPlateau"]},{"cell_type":"markdown","metadata":{},"source":["Specifying global parameters"]},{"cell_type":"code","execution_count":4,"metadata":{"trusted":true},"outputs":[],"source":["img_h,img_w= (224,224)\n","batch_size=128\n","epochs=100\n","n_class=3"]},{"cell_type":"markdown","metadata":{},"source":["*Concatenating train and test directory paths..*"]},{"cell_type":"code","execution_count":5,"metadata":{"trusted":true},"outputs":[],"source":["base_dir = '/home/bce19229/19bce229/Dataset/CDS/Class-Divided-SET/Output'\n","train_dir = os.path.join(base_dir, 'train')\n","validation_dir = os.path.join(base_dir, 'test')"]},{"cell_type":"markdown","metadata":{},"source":["Initializing train and test datagenerators"]},{"cell_type":"code","execution_count":6,"metadata":{"trusted":true},"outputs":[],"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","train_datagen = ImageDataGenerator(\n","         rescale=1./255,\n","         rotation_range=20,  # randomly rotate images in the range (degrees, 0 to 180)\n","        zoom_range = 0.1, # Randomly zoom image \n","        width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)\n","        height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)\n","        horizontal_flip=True,  # randomly flip images\n","        vertical_flip=False)  # randomly flip images\n","\n","test_datagen= ImageDataGenerator(rescale=1./255)"]},{"cell_type":"code","execution_count":7,"metadata":{"trusted":true},"outputs":[],"source":["from tensorflow.keras.optimizers import Adam,SGD,Adagrad,Adadelta,RMSprop\n","\n","reduce_learning_rate = ReduceLROnPlateau(monitor='loss',\n","                                         factor=0.1,\n","                                         patience=3,\n","                                         cooldown=2,\n","                                         min_lr=1e-10,\n","                                         verbose=1)\n","\n","callbacks = [reduce_learning_rate]\n","optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)"]},{"cell_type":"markdown","metadata":{},"source":["Compiling Models"]},{"cell_type":"code","execution_count":8,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 4759 images belonging to 3 classes.\n","Found 598 images belonging to 3 classes.\n"]}],"source":["train_generator = train_datagen.flow_from_directory(\n","                    train_dir,                   # This is the source directory for training images\n","                    target_size=(img_h, img_w),  # All images will be resized to 300x300\n","                    batch_size=batch_size,\n","                    class_mode='categorical')\n","\n","\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","validation_generator = test_datagen.flow_from_directory(\n","                        validation_dir,\n","                        target_size=(img_h, img_w),\n","                        batch_size=batch_size,\n","                        class_mode='categorical')"]},{"cell_type":"markdown","metadata":{},"source":["Now lets fit the models on our dataset"]},{"cell_type":"code","execution_count":9,"metadata":{"trusted":true},"outputs":[],"source":["# history_1 = model_1.fit(\n","#       train_generator,\n","#       steps_per_epoch=6528//batch_size, \n","#       epochs=epochs,\n","#       validation_data=validation_generator,\n","#       validation_steps=3312//batch_size,  \n","#       callbacks=callbacks,\n","#       verbose=1)"]},{"cell_type":"code","execution_count":10,"metadata":{"trusted":true},"outputs":[],"source":["# history_2 = model_2.fit(\n","#       train_generator,\n","#       steps_per_epoch=6528//batch_size, \n","#       epochs=epochs,\n","#       validation_data=validation_generator,\n","#       validation_steps=3312//batch_size,  \n","#       callbacks=callbacks,\n","#       verbose=1)"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["2022-12-11 15:53:46.978848: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n","2022-12-11 15:53:46.981291: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n","2022-12-11 15:53:47.016375: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n","2022-12-11 15:53:47.016427: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (mtechcse-Precision-7920-Tower): /proc/driver/nvidia/version does not exist\n","2022-12-11 15:53:47.017392: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2022-12-11 15:53:47.020001: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n"]}],"source":["# from keras.models import load_model\n","# model1 = tf.keras.models.load_model('/home/bce19229/19bce229/Code/saved Models/Pretrained DenseNet121/DenseNet121-model.h5')\n","model2 = tf.keras.models.load_model('/home/bce19229/19bce229/Code/saved Models/Pretrained DenseNet169/DenseNet169-model.h5')\n","model3 = tf.keras.models.load_model('/home/bce19229/19bce229/Code/saved Models/Pretrained InceptionResNetV2/InceptionResNetV2-best-model.h5')"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["model4 = tf.keras.models.load_model('/home/bce19229/19bce229/Code/saved Models/Pretrained mobilenetv2/mobilenetv2-best-model.h5')"]},{"cell_type":"code","execution_count":13,"metadata":{"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/bce19229/miniconda3/envs/tf_gpu/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n","  warnings.warn('`Model.predict_generator` is deprecated and '\n","2022-12-11 15:54:39.653135: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n","2022-12-11 15:54:39.671719: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3000000000 Hz\n"]},{"name":"stdout","output_type":"stream","text":["38/38 [==============================] - 966s 25s/step\n","5/5 [==============================] - 110s 20s/step\n","25/38 [==================>...........] - ETA: 5:40"]}],"source":["from deepstack.base import KerasMember\n","# with tf.device('/GPU:0'):\n","# member1 = KerasMember(name=\"model1\", keras_model=model1, train_batches=train_generator, val_batches=validation_generator)\n","member2 = KerasMember(name=\"model2\", keras_model=model2, train_batches=train_generator, val_batches=validation_generator)\n","member3 = KerasMember(name=\"model3\", keras_model=model3, train_batches=train_generator, val_batches=validation_generator)\n","member4 = KerasMember(name=\"model4\", keras_model=model4, train_batches=train_generator, val_batches=validation_generator)\n","# member5 = KerasMember(name=\"model5\", keras_model=model5, train_batches=train_generator, val_batches=validation_generator)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["model1 - Weight: 0.0362 - accuracy_score: 0.7180\n","model2 - Weight: 0.9638 - accuracy_score: 0.7392\n","DirichletEnsemble accuracy_score: 0.7418\n"]}],"source":["from deepstack.ensemble import DirichletEnsemble\n","from sklearn.metrics import accuracy_score\n","\n","wAvgEnsemble = DirichletEnsemble(N=10000, metric=accuracy_score)\n","wAvgEnsemble.add_members([member4, member2, member3])\n","wAvgEnsemble.fit()\n","wAvgEnsemble.describe()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["sklearn version must be >= 0.22. You have: 1.0.2\n","Calling predict\n","model1 - accuracy_score: 0.7180\n","model2 - accuracy_score: 0.7392\n","StackEnsemble accuracy_score: 0.5736\n"]},{"name":"stderr","output_type":"stream","text":["/home/bce19229/miniconda3/envs/tf_gpu/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n"]},{"data":{"text/plain":["0.5735785953177257"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["from deepstack.ensemble import StackEnsemble\n","import sklearn\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.ensemble import StackingClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.ensemble import ExtraTreesClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","\n","#Ensure you have the scikit-learn version >= 0.22 installed\n","print(\"sklearn version must be >= 0.22. You have:\", sklearn.__version__)\n","\n","stack = StackEnsemble()\n","\n","# 2nd Level Meta-Learner\n","estimators = [\n","    ('rf', RandomForestClassifier(verbose=0, n_estimators=100, max_depth=15, n_jobs=20, min_samples_split=30)),\n","    ('etr', ExtraTreesClassifier(verbose=0, n_estimators=100, max_depth=10, n_jobs=20, min_samples_split=20)),\n","    ('dtc',DecisionTreeClassifier(random_state=0, max_depth=3))\n","]\n","# 3rd Level Meta-Learner\n","clf = StackingClassifier(\n","    estimators=estimators, final_estimator=LogisticRegression()\n",")\n","\n","stack.model = clf\n","stack.add_members([member1, member2, member 3])\n","stack.fit()\n","stack.describe(metric=sklearn.metrics.accuracy_score)"]},{"cell_type":"markdown","metadata":{},"source":["Now lets save our stack-ensemble model."]},{"cell_type":"markdown","metadata":{},"source":["Saves meta-learner and base-learner of ensemble into folder / directory.\n","\n","**Args:**\n","* folder: the folder where models should be saved to(Create if not exists).           "]},{"cell_type":"code","execution_count":16,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["<StackEnsemble: [model1, model2]>"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["stack.save()"]},{"cell_type":"markdown","metadata":{},"source":["Loading the model is as simple as this."]},{"cell_type":"code","execution_count":17,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Loaded model1\n","Loaded model2\n"]},{"data":{"text/plain":["<StackEnsemble: [model1, model2]>"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["stack.load()"]},{"cell_type":"markdown","metadata":{},"source":["Don't forget to save the DCNN itself, otherwise you may have trouble."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[{"ename":"NameError","evalue":"name 'model_1' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn [18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model_json \u001b[39m=\u001b[39m model_1\u001b[39m.\u001b[39mto_json()\n","\u001b[0;31mNameError\u001b[0m: name 'model_1' is not defined"]}],"source":["# model_json = model_1.to_json()\n","# with open(\"VGG_19.json\", \"w\") as json_file:\n","#     json_file.write(model_json)\n","# # serialize weights to HDF5\n","# model_1.save_weights(\"VGG_19_weights.h5\")\n","# print(\"Saved VGG19 to disk\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Saved Inception_V3 to disk\n"]}],"source":["# model_json = model_2.to_json()\n","# with open(\"Inception_V3.json\", \"w\") as json_file:\n","#     json_file.write(model_json)\n","# # serialize weights to HDF5\n","# model_2.save_weights(\"Inception_V3_weights.h5\")\n","# print(\"Saved Inception_V3 to disk\")"]},{"cell_type":"markdown","metadata":{},"source":["**I encourage all of you to play around with this kernel, change the hyperparameters and meta learners. This ensembling is going to help you a lot in different kaggle competitions.And please give me an upvote, it motivates me to work more. :)**"]}],"metadata":{"kernelspec":{"display_name":"tf_gpu","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.15"},"vscode":{"interpreter":{"hash":"29f65a1a5988b626856b716a6de45aa393dd7de687b910f982e4ffa38e02e83e"}}},"nbformat":4,"nbformat_minor":4}
